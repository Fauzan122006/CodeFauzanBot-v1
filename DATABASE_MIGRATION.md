# Database Migration Guide - Production Ready

## Current Issues with JSON Storage:

### ğŸš¨ **Critical Problems:**
1. **Data Loss Risk** - File corruption on crash
2. **No Atomic Writes** - Race conditions
3. **Memory Bloat** - All data in RAM
4. **Poor Performance** - Writes entire file every time
5. **No Backup Strategy** - Single point of failure

---

## âœ… **Recommended Solutions:**

### **Option 1: Better JSON (Quick Fix - 1 hour)**
**Good for:** < 500 active users

**Features:**
- âœ… Atomic writes (temp file + rename)
- âœ… Auto-backup system (keeps last 10)
- âœ… Data corruption recovery
- âœ… Save queue prevents concurrent writes
- âœ… Validation before commit

**Implementation:** Use `userDataHandler.SAFE.js`

**Pros:**
- Easy migration (just replace file)
- No new dependencies
- Works with current code

**Cons:**
- Still loads all data to memory
- Slow with 1,000+ users
- No concurrent access

---

### **Option 2: SQLite (Recommended - 2-3 hours)**
**Good for:** 500 - 50,000 users

**Why SQLite:**
- âœ… Serverless (no setup needed)
- âœ… ACID compliance (no data loss)
- âœ… Automatic locking
- âœ… Incremental updates (only changed data)
- âœ… Indexes for fast queries
- âœ… Built-in backup (.backup command)
- âœ… Low memory footprint

**Setup:**
```bash
npm install better-sqlite3
```

**Schema:**
```sql
CREATE TABLE users (
    user_id TEXT PRIMARY KEY,
    guilds TEXT NOT NULL  -- JSON of guild data
);

CREATE TABLE guild_users (
    user_id TEXT,
    guild_id TEXT,
    xp INTEGER DEFAULT 0,
    level INTEGER DEFAULT 1,
    messageCount INTEGER DEFAULT 0,
    achievements TEXT,  -- JSON array
    activeTime INTEGER DEFAULT 0,
    voiceTime INTEGER DEFAULT 0,
    lastActive INTEGER,
    joinDate INTEGER,
    coins INTEGER DEFAULT 0,
    -- ... other fields
    PRIMARY KEY (user_id, guild_id)
);

CREATE INDEX idx_guild_xp ON guild_users(guild_id, xp DESC);
CREATE INDEX idx_guild_level ON guild_users(guild_id, level DESC);
```

**Migration Script:**
```javascript
const Database = require('better-sqlite3');
const fs = require('fs');

// Read current JSON data
const userData = JSON.parse(fs.readFileSync('./database/userData.json'));

// Create SQLite database
const db = new Database('./database/userData.db');

// Create schema
db.exec(`
    CREATE TABLE IF NOT EXISTS guild_users (
        user_id TEXT,
        guild_id TEXT,
        xp INTEGER DEFAULT 0,
        level INTEGER DEFAULT 1,
        messageCount INTEGER DEFAULT 0,
        achievements TEXT,
        activeTime INTEGER DEFAULT 0,
        voiceTime INTEGER DEFAULT 0,
        lastActive INTEGER,
        joinDate INTEGER,
        reactionsGiven INTEGER DEFAULT 0,
        memeCount INTEGER DEFAULT 0,
        supportMessages INTEGER DEFAULT 0,
        totalGameTime INTEGER DEFAULT 0,
        eventCount INTEGER DEFAULT 0,
        isBooster INTEGER DEFAULT 0,
        coins INTEGER DEFAULT 0,
        PRIMARY KEY (user_id, guild_id)
    );
    
    CREATE INDEX IF NOT EXISTS idx_guild_xp ON guild_users(guild_id, xp DESC);
`);

// Migrate data
const insert = db.prepare(`
    INSERT OR REPLACE INTO guild_users VALUES (
        ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?
    )
`);

const insertMany = db.transaction((users) => {
    for (const [userId, data] of Object.entries(users)) {
        if (!data.guilds) continue;
        
        for (const [guildId, guildData] of Object.entries(data.guilds)) {
            insert.run(
                userId,
                guildId,
                guildData.xp || 0,
                guildData.level || 1,
                guildData.messageCount || 0,
                JSON.stringify(guildData.achievements || []),
                guildData.activeTime || 0,
                guildData.voiceTime || 0,
                guildData.lastActive,
                guildData.joinDate,
                guildData.reactionsGiven || 0,
                guildData.memeCount || 0,
                guildData.supportMessages || 0,
                guildData.totalGameTime || 0,
                guildData.eventCount || 0,
                guildData.isBooster ? 1 : 0,
                guildData.coins || 0
            );
        }
    }
});

insertMany(userData);

console.log('Migration complete!');
```

**New userDataHandler.js:**
```javascript
const Database = require('better-sqlite3');
const db = new Database('./database/userData.db');

// Prepare statements (cached for performance)
const stmts = {
    getUser: db.prepare('SELECT * FROM guild_users WHERE user_id = ? AND guild_id = ?'),
    insertUser: db.prepare(`
        INSERT OR REPLACE INTO guild_users 
        (user_id, guild_id, xp, level, messageCount, achievements, ...)
        VALUES (?, ?, ?, ?, ?, ?, ...)
    `),
    updateXP: db.prepare('UPDATE guild_users SET xp = ?, level = ? WHERE user_id = ? AND guild_id = ?'),
    incrementMessages: db.prepare('UPDATE guild_users SET messageCount = messageCount + 1 WHERE user_id = ? AND guild_id = ?'),
    getLeaderboard: db.prepare('SELECT * FROM guild_users WHERE guild_id = ? ORDER BY xp DESC LIMIT 100')
};

function initUser(userId, guildId) {
    let user = stmts.getUser.get(userId, guildId);
    
    if (!user) {
        stmts.insertUser.run(
            userId, guildId, 0, 1, 0, '[]', 0, 0, Date.now(), Date.now(), 0, 0, 0, 0, 0, 0, 0
        );
        user = stmts.getUser.get(userId, guildId);
    }
    
    return user;
}

function updateUserData(userId, guildId, data) {
    const updates = Object.entries(data)
        .map(([key, value]) => `${key} = ?`)
        .join(', ');
    
    const values = Object.values(data);
    values.push(userId, guildId);
    
    db.prepare(`UPDATE guild_users SET ${updates} WHERE user_id = ? AND guild_id = ?`).run(...values);
}

// Automatic backup every hour
setInterval(() => {
    db.backup(`./database/backups/userData_${Date.now()}.db`);
    console.log('[Database] Backup created');
}, 60 * 60 * 1000);
```

**Pros:**
- âš¡ 10-100x faster than JSON
- ğŸ’¾ Low memory usage
- ğŸ”’ No data corruption
- ğŸ“Š Advanced queries (leaderboards, etc)
- ğŸ”„ Easy replication

**Cons:**
- Requires code changes
- New dependency
- Learning curve

---

### **Option 3: MongoDB (For Scale - 4-6 hours)**
**Good for:** 50,000+ users or distributed systems

**Why MongoDB:**
- âœ… Cloud-ready (MongoDB Atlas free tier)
- âœ… Horizontal scaling
- âœ… Replica sets (auto-failover)
- âœ… Flexible schema
- âœ… Built-in aggregation

**Cons:**
- External service dependency
- Overkill for small bots

---

## ğŸ“Š **Performance Comparison:**

| Method | Users | Write Speed | Memory | Corruption Risk | Setup Time |
|--------|-------|-------------|--------|-----------------|------------|
| **Current JSON** | < 100 | Slow | High | **High** ğŸš¨ | 0 min |
| **Safe JSON** | < 500 | Medium | High | Low | 5 min |
| **SQLite** | < 50k | **Fast** | **Low** | **None** | 2 hours |
| **MongoDB** | Unlimited | **Fast** | **Low** | **None** | 4 hours |

---

## ğŸ¯ **Recommendation:**

### **For Your Bot:**
Based on current size:

1. **Immediate (Today):** Replace with `userDataHandler.SAFE.js`
   - 5 minute fix
   - Prevents data loss
   - Buys time for proper migration

2. **This Week:** Migrate to SQLite
   - 2-3 hours work
   - Production-ready
   - Future-proof for growth

3. **Future (>10k users):** Consider MongoDB Atlas
   - Cloud backup
   - Global distribution
   - Auto-scaling

---

## ğŸ”§ **Implementation Priority:**

**Phase 1 (NOW - 5 min):**
- âœ… Atomic writes with backup
- âœ… Data corruption prevention
- âœ… Recovery system

**Phase 2 (This Week - 3 hours):**
- âœ… SQLite migration
- âœ… Indexed queries
- âœ… Better performance

**Phase 3 (Future - as needed):**
- âœ… Redis caching
- âœ… MongoDB/PostgreSQL
- âœ… Multi-region replication

---

## ğŸ“ **Migration Checklist:**

### Safe JSON (Quick):
- [ ] Copy `userDataHandler.SAFE.js` to `userDataHandler.js`
- [ ] Create `database/backups` folder
- [ ] Restart bot
- [ ] Verify backups are created

### SQLite (Recommended):
- [ ] `npm install better-sqlite3`
- [ ] Run migration script
- [ ] Update userDataHandler.js
- [ ] Test all features
- [ ] Setup auto-backup
- [ ] Monitor for 24 hours
- [ ] Archive old JSON as fallback

---

## âš ï¸ **Data Loss Prevention Checklist:**

Current JSON system risks:
- [x] âŒ Crash during write = corrupt file
- [x] âŒ Concurrent writes = data loss
- [x] âŒ No validation = bad data persists
- [x] âŒ No backups = total loss possible

With Safe JSON:
- [x] âœ… Atomic writes (safe)
- [x] âœ… Auto-backup (10 copies)
- [x] âœ… Validation before commit
- [x] âœ… Recovery system

With SQLite:
- [x] âœ… ACID transactions
- [x] âœ… Write-ahead logging
- [x] âœ… Automatic recovery
- [x] âœ… Point-in-time backup

---

Mau saya implement yang mana? 
1. Safe JSON (5 menit)
2. SQLite migration (2-3 jam)
3. Both (Safe JSON now, SQLite later)
